{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Spam_Detection_example.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bdmlworkshop/Examples/blob/main/Spam_Detection_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LhK_I2vc0Yo"
      },
      "source": [
        "# NLP Simple Spam SMS detection\n",
        "\n",
        "For this code along we will build a spam filter! We'll use the various NLP tools we learned about as well as a new classifier, Naive Bayes.\n",
        "\n",
        "We'll use a classic dataset for this - UCI Repository SMS Spam Detection: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U4VMCNygmui"
      },
      "source": [
        "!wget -q https://mirrors.netix.net/apache/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\n",
        "!tar -xzf spark-3.0.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# define some evironement variable diretly with python instruction using the module os\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/default-java\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_KD7izbgsA1"
      },
      "source": [
        "#Get The Data\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm-I2Hx6g_Qt"
      },
      "source": [
        "!unzip smsspamcollection.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDtPuMarc0Yz"
      },
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6Cz74X5c0Y4"
      },
      "source": [
        "spark = SparkSession.builder.appName('BDML_smsSpam').getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSVZNoSrc0Y-"
      },
      "source": [
        "data = spark.read.csv(\"SMSSpamCollection\",inferSchema=True,sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7t14XCsc0ZC"
      },
      "source": [
        "data = data.withColumnRenamed('_c0','class').withColumnRenamed('_c1','text')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK1XFaZCc0ZE"
      },
      "source": [
        "data.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nOOUuWWc0ZI"
      },
      "source": [
        "## Clean and Prepare the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdPwV4agc0ZI"
      },
      "source": [
        "**Create a new length feature:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iid_FOfic0ZI"
      },
      "source": [
        "from pyspark.sql.functions import length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWPj3HZtc0ZL"
      },
      "source": [
        "data = data.withColumn('length',length(data['text']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC4GOBg7c0ZO"
      },
      "source": [
        "data.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIudRRB1c0ZS"
      },
      "source": [
        "# Pretty Clear Difference\n",
        "data.groupby('class').mean().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BbCCAGgc0ZU"
      },
      "source": [
        "## Feature Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuyQ1aM4c0ZU"
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer,StopWordsRemover, CountVectorizer,IDF,StringIndexer\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
        "count_vec = CountVectorizer(inputCol='stop_tokens',outputCol='c_vec')\n",
        "idf = IDF(inputCol=\"c_vec\", outputCol=\"tf_idf\")\n",
        "ham_spam_to_num = StringIndexer(inputCol='class',outputCol='label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOjeGTHec0ZX"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w44E1723c0ZZ"
      },
      "source": [
        "clean_up = VectorAssembler(inputCols=['tf_idf','length'],outputCol='features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRqQ7bDxc0Zb"
      },
      "source": [
        "### The Model\n",
        "\n",
        "We'll use Naive Bayes, but feel free to play around with this choice!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v0vf_rVc0Zb"
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xthFEcEc0Zf"
      },
      "source": [
        "# Use defaults\n",
        "nb = NaiveBayes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGjup1FBc0Zh"
      },
      "source": [
        "### Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XbqLXCDc0Zi"
      },
      "source": [
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EI5yC28c0Zl"
      },
      "source": [
        "data_prep_pipe = Pipeline(stages=[ham_spam_to_num,tokenizer,stopremove,count_vec,idf,clean_up])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6PtEGgyc0Zn"
      },
      "source": [
        "cleaner = data_prep_pipe.fit(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_tGuzt6c0Zp"
      },
      "source": [
        "clean_data = cleaner.transform(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tqDE3QGc0Zr"
      },
      "source": [
        "### Training and Evaluation!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_6Zh3uKc0Zs"
      },
      "source": [
        "clean_data = clean_data.select(['label','features'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O74oHgmec0Zu"
      },
      "source": [
        "clean_data.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48OTLGfPc0Zx"
      },
      "source": [
        "(training,testing) = clean_data.randomSplit([0.7,0.3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5JaMVDTc0Z1"
      },
      "source": [
        "spam_predictor = nb.fit(training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4klYuK7c0Z3"
      },
      "source": [
        "data.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO15cfShc0Z5"
      },
      "source": [
        "test_results = spam_predictor.transform(testing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTfrxY-wc0Z7"
      },
      "source": [
        "test_results.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUakI6p8c0Z9"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFQNxPflc0aB"
      },
      "source": [
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(f\"Accuracy of model at predicting spam was: {acc}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiTovlFuc0aD"
      },
      "source": [
        "Not bad considering we're using straight math on text data! Try switching out the classification models! Or even try to come up with other engineered features!\n",
        "\n",
        "## Great Job!"
      ]
    }
  ]
}